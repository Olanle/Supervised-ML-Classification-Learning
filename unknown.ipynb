{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Neural Network from Scratch\n"
      ],
      "metadata": {
        "id": "Yt7vUpYbb4oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)  # derivative of sigmoid"
      ],
      "metadata": {
        "id": "seANODn2amNz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs (4 samples, 2 features)\n",
        "X = np.array([[0,0],\n",
        "              [0,1],\n",
        "              [1,0],\n",
        "              [1,1]])\n",
        "\n",
        "# target output\n",
        "y = np.array([[0],\n",
        "              [1],\n",
        "              [1],\n",
        "              [0]])"
      ],
      "metadata": {
        "id": "aNt-J2VLauy8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Parameters\n",
        "\n",
        "Let’s use:\n",
        "\n",
        "2 input neurons\n",
        "\n",
        "2 hidden neurons\n",
        "\n",
        "1 output neuron"
      ],
      "metadata": {
        "id": "MkL3iYYKdhKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "input_neurons = 2\n",
        "hidden_neurons = 2\n",
        "output_neurons = 1\n",
        "\n",
        "# randomly initialize weights and biases\n",
        "W1 = np.random.uniform(size=(input_neurons, hidden_neurons))\n",
        "b1 = np.random.uniform(size=(1, hidden_neurons))\n",
        "W2 = np.random.uniform(size=(hidden_neurons, output_neurons))\n",
        "b2 = np.random.uniform(size=(1, output_neurons))\n",
        "\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "Y2UcbuS-azp2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "input_neurons = 2\n",
        "hidden_neurons = 2\n",
        "output_neurons = 1\n",
        "\n",
        "# randomly initialize weights and biases\n",
        "W1 = np.random.uniform(size=(input_neurons, hidden_neurons))\n",
        "b1 = np.random.uniform(size=(1, hidden_neurons))\n",
        "W2 = np.random.uniform(size=(hidden_neurons, output_neurons))\n",
        "b2 = np.random.uniform(size=(1, output_neurons))\n",
        "\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "o2uSPcLUa3fN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10000):\n",
        "    # ---- Forward Pass ----\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)  # prediction\n",
        "\n",
        "    # ---- Compute Loss (Mean Squared Error) ----\n",
        "    loss = np.mean((y - a2)**2)\n",
        "\n",
        "    # ---- Backward Pass ----\n",
        "    # derivative of loss w.r.t output\n",
        "    d_a2 = (y - a2)\n",
        "    d_z2 = d_a2 * sigmoid_derivative(a2)\n",
        "\n",
        "    dW2 = np.dot(a1.T, d_z2)\n",
        "    db2 = np.sum(d_z2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_z2, W2.T)\n",
        "    d_z1 = d_a1 * sigmoid_derivative(a1)\n",
        "\n",
        "    dW1 = np.dot(X.T, d_z1)\n",
        "    db1 = np.sum(d_z1, axis=0, keepdims=True)\n",
        "\n",
        "    # ---- Gradient Descent Update ----\n",
        "    W1 += learning_rate * dW1\n",
        "    b1 += learning_rate * db1\n",
        "    W2 += learning_rate * dW2\n",
        "    b2 += learning_rate * db2\n",
        "\n",
        "    # (optional) print progress\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch} | Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGd-EHLLa7J5",
        "outputId": "db932092-f374-4bf1-cfa3-d6661dfef2be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss: 0.3247\n",
            "Epoch 1000 | Loss: 0.2406\n",
            "Epoch 2000 | Loss: 0.1960\n",
            "Epoch 3000 | Loss: 0.1207\n",
            "Epoch 4000 | Loss: 0.0305\n",
            "Epoch 5000 | Loss: 0.0125\n",
            "Epoch 6000 | Loss: 0.0074\n",
            "Epoch 7000 | Loss: 0.0051\n",
            "Epoch 8000 | Loss: 0.0038\n",
            "Epoch 9000 | Loss: 0.0031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFinal predictions:\")\n",
        "print(a2.round(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCMydLPWbAaR",
        "outputId": "f564e361-46d6-4327-aef8-0b4b980a4e33"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final predictions:\n",
            "[[0.053]\n",
            " [0.952]\n",
            " [0.952]\n",
            " [0.052]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the XOR Neural Network with Keras\n"
      ],
      "metadata": {
        "id": "XHeChrUWcWGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "l6W6jyn_cewk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input data\n",
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "\n",
        "# Target output\n",
        "y = np.array([[0],\n",
        "              [1],\n",
        "              [1],\n",
        "              [0]])"
      ],
      "metadata": {
        "id": "t9HdtOjhc-wr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Model\n",
        "\n",
        "We’ll use:\n",
        "\n",
        "2 neurons in the input layer\n",
        "\n",
        "2 neurons in the hidden layer (with ReLU activation)\n",
        "\n",
        "1 neuron in the output layer (with Sigmoid activation)"
      ],
      "metadata": {
        "id": "FHLXZqfrdMtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(2, input_dim=2, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "DdTepJcedDKq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function: measures error (binary_crossentropy for binary output)\n",
        "\n",
        "Optimizer: algorithm that updates weights (SGD here)\n",
        "\n",
        "Metrics: what to monitor (accuracy)"
      ],
      "metadata": {
        "id": "HjPMAxPSd5z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=SGD(learning_rate=0.3),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bXvwkoTJd6-c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, y, epochs=10000, verbose=0)"
      ],
      "metadata": {
        "id": "j76KeWF4d-Jz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate final performance\n",
        "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print(f\"Final Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "predictions = model.predict(X)\n",
        "print(\"\\nPredictions:\")\n",
        "print(np.round(predictions, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3Xno39WeIZg",
        "outputId": "f67015d9-8cd6-4ad7-a5c2-fd3720f842e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Loss: 0.4775, Accuracy: 0.7500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\n",
            "Predictions:\n",
            "[[0.333]\n",
            " [1.   ]\n",
            " [0.333]\n",
            " [0.333]]\n"
          ]
        }
      ]
    }
  ]
}